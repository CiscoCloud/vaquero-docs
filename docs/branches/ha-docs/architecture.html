<head>
      
<meta charset="UTF-8"> <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]--> <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>
Vaquero Architecture
</title>
      
<link rel="stylesheet" type="text/css" href="../doc.css"> <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400"> <link rel='shortcut icon' href='cow.png' type='image/x-icon'/ >
<style>
        .markdown-body {
          box-sizing: border-box;
          min-width: 200px;
          max-width: 1200px;
          margin: 0 auto;
          padding: 45px;
        }
      </style>
</head><article class="markdown-body">

<h1 id="vaquero-architecture">Vaquero: Architecture</h1>
<p><a href="https://ciscocloud.github.io/vaquero-docs/">Home</a> | <a href="https://github.com/CiscoCloud/vaquero-docs/tree/master">Docs Repo</a></p>
<p><strong>Last Updated</strong>: February 2017</p>
<p>Vaquero is designed to simplify the provisioning and ongoing operations of clustered software on bare metal infrastructure. A running Vaquero system is composed of a centralized control plane that automates provisioning of software in one or more data centers, and remote agents that take actions on boot hosts.</p>
<p>The goal is to provide the ability for teams to manage their infrastructure using the same tools they use for their applications (revision control, CI/CD pipeline, etc.), to and enable similar workflows including automated updates, gating, immutability, and A/B deployments. The final outcome will be a fully operational data center running heterogeneous deployments of clustered software on bare metal, with fully automated deployment and upgrades driven by a CI pipeline.</p>
<h2 id="architecture">Architecture</h2>
<p>Vaquero is delivered in one container for operational simplicity. Vaquero can run in multiple modes, including server, agent, and standalone (the combination of server and agent).</p>
<div class="figure">
<img src="jan17Arch.png" />
</div>
<h4 id="vaquero-server"><code>vaquero server</code></h4>
<p>The <code>vaquero</code> container in <code>server</code> mode implements the logic to receive updates from sources of truth and process the data model and make it a reality by providing information to agents. The vaquero server cluster leverages etcd to persist state, data models and configurations. Servers never call down to agents, they simply act as a distributed message queue for agents to fetch updates from, enabling scalable distributed servers.</p>
<ol style="list-style-type: decimal">
<li><strong>user API (in progress)</strong> - REST API for users to interact with the system and provide operational insights into booting hosts.</li>
<li><strong>updater</strong> - The interface that SoT's will go through to update their data models, could be listening for github webhooks or watching a source of truth directory for modifications.</li>
<li><strong>model API</strong> - REST API that responds to agents looking to update their model cache, it will also provide a state manifest that enables an agent to know what state its booting hosts are in.</li>
<li><strong>event API</strong> - REST API that receives events from long running services on agents.</li>
<li><strong>server controller</strong> - The process that manages the numerous go routines on vaquero servers and acts as an intermediary between all server services.</li>
<li><strong>state engine</strong> - The brains behind vaquero; will understand a data model, look at the events history and task history to understand what actions need to be taken to move booting hosts from one state to the next.</li>
<li><strong>task manager</strong> - A generic container task manager that knows how to run jobs on distributed task executors. A use case will be to run LOM containers that will execute on an agent to reboot a host, kicking off the re-provision process.</li>
</ol>
<h4 id="vaquero-agent"><code>vaquero agent</code></h4>
<p>The <code>vaquero</code> container running in <code>agent</code> mode registers itself with an upstream vaquero server and drives provisioning in a local datacenter. The agent is designed in such a way that it is stateless, agents can be created and destroyed at will. They will obtain state, configuration, actions from the vaquero server cluster.</p>
<ol style="list-style-type: decimal">
<li><strong>model cache</strong> - is the local cached representation of the infrastructure, the model cache handles updating with the vaquero server cluster just in time when the vaquero agent needs it. It can also be used during network outages, so agents can still serve their booting hosts without connection to the server cluster.</li>
<li><strong>agent controller</strong> - The process that manages multiple go-routines and acts as an intermediary between agent services.</li>
<li><strong>DHCP</strong> - a DHCP server implemented in go that can run as a DHCP proxy, serving network boot details only, or as a fully featured DHCP server providing IP addresses and network boot details. Validated to work with a DHCP relay as well.</li>
<li><strong>TFTP</strong> - a TFTP server that only serves the <a href="http://ipxe.org/howto/chainloading"><code>undionly.kpxe</code> file</a>.</li>
<li><strong>asset HTTP server</strong> - implements a file server or reverse proxy to forward requests to a CDN. This delivers unattend boot scripts, kernels, and initrds.</li>
<li><strong>event client</strong> - an HTTP client that reports long running service events back (DHCP, TFTP, HTTP) to the vaquero server cluster. (the servers leverage this information to understand what state booting hosts are in)</li>
<li><strong>task executor</strong> - a generic container execution runtime. It will receive &quot;tasks&quot; or containers to run from a centralized task manager, run it and return the exit code and logs. Vaquero will leverage this for LOM management and running pre-reboot and post-reboot containers to flush and validate state on a host.</li>
</ol>
<h4 id="walking-through-a-data-model-update">Walking through a data model update</h4>
<ol style="list-style-type: decimal">
<li>SoT updated</li>
<li>updater fetches update</li>
<li>server controller receives event and stores model in etcd</li>
<li>state engine computes differences between current state and new desired state from the SoT.</li>
<li>state engine creates LOM tasks for related task executors to reboot hosts</li>
<li>vaquero agent task executor obtains and runs LOM task to reboot hosts</li>
<li>host boots and begins DHCP / TFTP / HTTP process in network boot</li>
<li>model cache and state manifest is updated via model API for the above 3 services (just in time updating)</li>
<li>events are reported to vaquero server</li>
<li>state engine observes events status and tasks status and will act until desired state is reached</li>
</ol>
<h2 id="ha-vaquero">HA Vaquero</h2>
<div class="figure">
<img src="jan17HA.png" />
</div>
<p>The diagram above depicts a production deployment of Vaquero. Vaquero implements its own leader election, and also contains a readiness probe to integrate with kubernetes deployments.</p>
<h4 id="running-vaquero-with-internal-ha">Running vaquero with internal HA</h4>
<p>Vaquero implements leader election using Etcd's <a href="https://godoc.org/github.com/coreos/etcd/clientv3/concurrency">built in leader election</a>. Our procedure works by giving every vaquero server a unique ID. All running servers campaign on the same Etcd &quot;leader&quot; key, and attempt to put their own unique IDs as the &quot;leader&quot; value. One server will successfully become leader and serve as a fully-functional vaquero server, and the rest will continue to passively campaign. Should one of the vaquero servers exit, error out, or power off, another campaigning server will take on the role of leader within a fraction of a second.</p>
<p><em>Note</em>: Once a vaquero server errors out or temporarily loses contact with etcd, it is no longer permitted to continue campaigning. A failed vaquero server must be manually restarted to re-enter leader election. See the <a href="outage.html">outage document</a> to see how Vaquero handles failures.</p>
<p>Ensure you have toggled the <code>HA</code> configuration flag to <code>true</code> and that your etcd cluster is properly configured and healthy before implementing HA vaquero servers. To watch the current leader value from the command line, run <code>etcdctl elect -l leader</code>.</p>
<h4 id="ha-and-kubernetes">HA and Kubernetes</h4>
<p>Vaquero's readiness probe is baked into its leader election procedure. We expose a <code>/ready</code> endpoint via the vaquero UserAPI (default= <code>500</code>, not ready), and when a server becomes the elected leader, we write a <code>200</code> (ready) to the UserAPI server. This tells kubernetes that this server is the leader, and to direct traffic towards that server only. <em>Note</em>: Currently our <code>/live</code> (liveliness probe) endpoint is hardcoded to <code>200</code> as long as the vaquero server is up-- whether it is the active leader or passively campaigning. This may change in the future when the liveliness probe is developed further.</p>
<p>Further, with Kubernetes we recommend deploying two vaquero agents per broadcast domain, for operational safety. See the <a href="README.html">README</a> for details on production deployments, considerations, and requirements.</p>
